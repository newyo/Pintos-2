			+--------------------+
			|        CS 140      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

René Kijewski <kijewski@inf.fu-berlin.de>
Christian Mehlis <mehlis@inf.fu-berlin.de>

---- PRELIMINARIES ----

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

in struct thread:
int64_t wakeup;                     /* only used for sleep */
Variable gibt den Zeitpunkt des aufwachens in ticks an.

global:
static struct list sleep_list;
Nach wakeup sortierte Liste, in der die schlafenden Threads gespeichert sind.
Diese sind dann nicht mehr in der Readylist.

---- ALGORITHMS ----

In timer_sleep fügen wir den Thread mithilfe der "sleep_add (ticks)"-Funktion 
in die sleep_list ein. Diese ist sortiert: Wir verwenden "list_insert_ordered", 
um das nächste Element in O(1) bekommen zu können.
Jeden Tick wird überprüft, ob der HEAD von sleep_list aufgeweckt werden muss.
Auch nachfolgende Threads werden aufgeweckt, wenn ihre Wartezeit abgelaufen ist,
jedoch ermöglicht die Sortiertheit der Liste das frühe Verlassen der Schleife
innerhalb des Interruptskontexts.

---- SYNCHRONIZATION ----

Wir deaktivieren die Interupts für die Zeit der Listenoperation und stellen 
nach der Operation den Status wieder her.

---- RATIONALE ----

Dies erschien uns als die einzig Wahre Lösung.
Dies ist die intuitiv beste Lösung.
Hätten wir mehr Zeit zur Bearbeitung gehabt, hätten wir eine geeignetere
Datenstruktur als eine verkettete Liste implementiert.

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----
Aus einer ready_list werden 64 ready_listen. Jede Priorität hat eine eigene 
Liste  (thread.h)
static struct list ready_list[PRI_MAX + 1];

Die Liste aller Locks, die ein Thread besitzt, eingefügt in struct_thread.
struct list lock_list;              /* list of held locks */

In struct lock für struct thread::lock_list:
struct list_elem elem;      /* bookkeeping of being acquired */

In "thread_get_priority_of":
Zuerst werden Interupts disabled.
Ein Thread weiß, welche locks er hält. Ein lock weiß wiederum, welche Threads 
durch ihn blockiert werden. Die Priorität eines Threads ist das Max. aus seiner 
Ausgangspriorität und den Priorität der Threads, die durch ihn blockiert werden,
wodurch auch transitive Prioritätsvererbung ermöglicht wird.
Die 64 Listen wurden durch spätere Designänderungen unnötig, jedoch kamen wir
innerhalb der Bearbeitungszeit nicht dazu, sie wieder zu entfernen.

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

Im cond_signal wird der höchstpriorisierte wartende Thread gesucht und dessen
Semaphore geupt.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

Wenn das Lock bereits gehalten wurde, wird der Thread in die Liste der
blockierten Threads des Locks gesetzt. Er ruft thread_block auf. In thread.c
schedule wird reschedule_ready_lists aufgerufen, wodurch der Thread mit der
effektiv höchsten Priorität gefunden wird.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

lock_release upt die zugehörige Semaphore. Unter den wartenden Threads wird
der Thread mit der effektiv höchsten Priorität gesucht. Hat dieser eine
echtgrößere Priorität als der aktuelle Thread, yieldet derselbige.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

N/V

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

Wir denken, dass das Bookkeeping, welche Locks of jeweiligen Thread gehalten
werden schon die beste Möglichkeit ist. Mir fällt auch gar keine  andere ein.

			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

in "struct thread":

Der "nice"-Wert wird für jeden Thread in struct thread abgelegt:
    int nice;                           /* Niceness of the thread: bigger is nicer */

Jeder Thread kennt seine recent_cpu:
    fp_t recent_cpu;                    /* Recent CPU of this thread */

Globale Variable:
fp_t thread_load_avg;

Unsere fixed-point implementierung basiert auf:

#define _FP_T_SGN_LEN  (1)
#define _FP_T_INT_LEN  (17)
#define _FP_T_FRAC_LEN (14)

typedef struct fp_t fp_t;
struct fp_t
{
  uint16_t frac_part  : _FP_T_FRAC_LEN;
  uint32_t int_part   : _FP_T_INT_LEN;
  int8_t   signedness : _FP_T_SGN_LEN;
} __attribute__ ((packed));

Die Form wurde in der Aufgabe vorgegeben.

Für die Addition von Zahlen werden der Ganzzahlanteil und der gebrochene Anteil
einzeln Addiert und ein eventueller Übertrag in gebrochenen Anteil in den
Ganzzahlanteil inkrementiert.
Bei der Multiplikation und Division werden die Zahlen als geshiftete Zahlen
betrachtet und nach der Berechnung um den Shiftfaktor korrigiert.

Wir haben eine -0. :-)

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

N/V

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

N/V

Im Interruptkontext wird nur neu berechnet, alle anderen Operationen finden
außerhalb von Interrupts statt.

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

Die Verwendung von 64 Listen erschien uns anfangs für die nicht-MLFQS-Variante
sinnvoll. Leider stellte sie sich für MLFQS als schwierig kopmliziert und sollte
ggf. ersetzt werden.

Hätten wir mehr Zeit, würden wir für mlfqs einen Heap anstatt einer verketteten
Liste verwenden, so dass das herausziehen des größten Wertes beschleunigt wird
(O(1)). Ebenso könnte man dann die ungerundeten Festkommawerte als Key
verwenden. In thread_tick würde bei timer_ticks () % TIMER_FREQ ein komplett
neuer Heap aufgebaut und in thread_ticks >= TIME_SLICE der Key des eigenen
Threads aktualisiert. Diese Operation sollte sehr schnell sein.

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

Unsere fixed-point.h enthält fünfzehn Funktionen, angefangen vom Betrag, über
die Grundrechenarten bis hin zum Reziprokwert und Rundungen.
Unser fp_t Datentyp ist ein Struct, das Feldlängenangaben entsprechend den
vorgegebenen Werten verwendet. Die Reihenfolge der Felder in fp_t wurde so
gewählt, dass die Anzahl der Shiftoperationen zum Auslesen minimiert werden.
Die unteren 31 Bits entsprechen der echten geshifteten ganzen Zahl.

Makros, die direkt auf einem Integer operierten, wäre vermutlich um
Größenordnungen performanter, jedoch ließe sich die Implementierung auch sehr
einfach abändern, wenn die Festkommazahlen sich als Flaschenhals herausstellten.

Der Beweggrund, nicht direkt in Makros zu arbeiten, war, dass wir einfach
nachvollziehbare Algorithmen an dieser Stellen gegen schnelle vorgezogen haben.

Keine Abstraktion zu verwenden, sondern an jeder angebrachten Stelle die
entsprechende Mathematik zu benutzen, ist in jederlei Hinsicht abwegig.
